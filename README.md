# Kafka Order Processing System

**Student:** EG/2020/3833  
**Assignment:** Real-time Order Processing with Apache Kafka

---

## ğŸ“‹ Project Overview

This project implements a **real-time order processing system** using Apache Kafka with Avro serialization. The system demonstrates enterprise-grade message streaming with producer-consumer architecture, including advanced features like retry logic, Dead Letter Queue (DLQ), and real-time price aggregation.

### âœ¨ Key Features

- âœ… **Avro Serialization** - Schema-based message serialization using Confluent Schema Registry
- âœ… **Real-time Aggregation** - Running average calculation of order prices
- âœ… **Retry Logic** - Automatic retry mechanism with exponential backoff (up to 3 attempts)
- âœ… **Dead Letter Queue (DLQ)** - Failed messages are sent to DLQ after maximum retries
- âœ… **Web-based Dashboard** - Beautiful Flask UI for real-time monitoring
- âœ… **Docker Compose** - Complete containerized setup for Kafka ecosystem

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Kafka Broker â”‚â”€â”€â”€â”€â”€â–¶â”‚  Consumer   â”‚
â”‚  (Python)   â”‚      â”‚   (orders)   â”‚      â”‚  (Python)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                      â”‚
                            â–¼                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚Schema Registryâ”‚      â”‚  orders-dlq â”‚
                    â”‚  (Avro)      â”‚      â”‚   (Topic)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

1. **Zookeeper** - Manages Kafka cluster metadata
2. **Kafka Broker** - Message broker for order streaming
3. **Schema Registry** - Manages Avro schemas for message serialization
4. **Producer** - Generates random order messages
5. **Consumer** - Processes orders with aggregation and error handling
6. **Flask Web UI** - Real-time monitoring dashboard

---

## ğŸ“¦ Order Message Schema

```json
{
  "type": "record",
  "name": "Order",
  "namespace": "com.kafka.orders",
  "fields": [
    {"name": "orderId", "type": "string"},
    {"name": "product", "type": "string"},
    {"name": "price", "type": "float"}
  ]
}
```

### Sample Order
```json
{
  "orderId": "1001",
  "product": "Laptop",
  "price": 1299.99
}
```

---

## ğŸš€ Getting Started

### Prerequisites

- Docker Desktop (Windows 11)
- Python 3.11+
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Asam8385/Kafka_assignment_3833.git
cd kafka_assignment
```

2. **Install Python dependencies**
```bash
pip install -r requirements.txt
```

3. **Start Kafka ecosystem with Docker Compose**
```bash
docker-compose up -d
```

This will start:
- Zookeeper (port 2181)
- Kafka Broker (port 9092)
- Schema Registry (port 8081)

4. **Verify services are running**
```bash
docker-compose ps
```

---

## ğŸ® Running the Application

### Option 1: Web Dashboard (Recommended)

1. **Start the Flask web application**
```bash
python src/app.py
```

2. **Open your browser**
```
http://localhost:5000
```

3. **Click "START SYSTEM"** to begin producing and consuming orders

4. **Monitor real-time metrics:**
   - Producer: Total produced, recent orders
   - Consumer: Total consumed, running average price, successful/retried/DLQ counts

### Option 2: Standalone Components

**Run Producer only:**
```bash
python src/producer.py
```

**Run Consumer only:**
```bash
python src/consumer.py
```

**Run Terminal Dashboard:**
```bash
python src/dashboard.py
```

---

## ğŸ“Š Dashboard Screenshots

### System Running - Real-time Metrics
![Dashboard Running](./screenshots/terminal-dashboard.png)

### Live Order Processing
![Order Processing](./screenshots/flask.png)

The dashboard displays:
- **Producer Metrics**: Total orders produced, production rate, recent orders table
- **Consumer Metrics**: Total consumed, running average price, success/retry/DLQ counts
- **Recent Orders**: Live table showing processed orders with status badges
- **System Status**: Uptime counter and connection status

---

## ğŸ”§ Configuration

### Kafka Configuration (`docker-compose.yml`)

```yaml
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    ports: ["2181:2181"]
    
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports: ["9092:9092"]
    
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    ports: ["8081:8081"]
```

### Python Dependencies (`requirements.txt`)

```
confluent-kafka[avro]==2.3.0
avro-python3==1.10.2
rich==13.7.0
fastavro==1.9.0
flask==3.0.0
flask-socketio==5.3.5
python-socketio==5.10.0
```

---

## ğŸ¯ Features Implementation

### 1. Avro Serialization

- **Schema Definition**: `schemas/order.avsc`
- **Schema Registry Integration**: Automatic schema registration and versioning
- **Serialization**: Producer serializes orders to Avro format
- **Deserialization**: Consumer deserializes Avro messages back to Python objects

### 2. Real-time Aggregation

```python
# Running average calculation
self.running_average = sum(self.price_history) / len(self.price_history)
```

- Maintains last 100 prices in memory
- Calculates running average after each successful order
- Updates displayed in real-time on dashboard

### 3. Retry Logic

```python
# Exponential backoff retry
retry_count = self.retry_count.get(order_id, 0)
if retry_count < self.max_retries:
    time.sleep(2 ** retry_count)  # 2s, 4s, 8s
    # Retry processing
```

- **Maximum retries**: 3 attempts
- **Backoff strategy**: Exponential (2s, 4s, 8s)
- **Failure simulation**: 10% random failure rate for demonstration

### 4. Dead Letter Queue (DLQ)

- Failed messages after 3 retries â†’ `orders-dlq` topic
- Includes error metadata and timestamp
- Prevents message loss
- Allows manual inspection and reprocessing

---

## ğŸ“ˆ System Metrics

The dashboard tracks and displays:

### Producer Metrics
- Total orders produced
- Production rate (messages/sec)
- Recent orders with details (Order ID, Product, Price, Timestamp)

### Consumer Metrics
- Total orders consumed
- Successful processing count
- Retry attempts count
- DLQ message count
- Running average price (real-time aggregation)
- Recent processed orders with status

---

## ğŸ§ª Testing

### Simulated Failures

The consumer simulates random failures (10% rate) to demonstrate:
- Retry mechanism in action
- Exponential backoff
- DLQ routing after max retries

### Example Console Output

```
2025-11-21 22:16:45,641 - src.consumer - INFO - Processed order: 1003 - Smartphone - $1871.54
2025-11-21 22:16:45,641 - src.consumer - INFO - Running average: $1871.54
2025-11-21 22:16:46,349 - src.consumer - ERROR - Error processing order 1005: Simulated temporary processing failure
2025-11-21 22:16:46,349 - src.consumer - INFO - Retrying order 1005 (attempt 1/3)
```

---

## ğŸ› ï¸ Troubleshooting

### Issue: Schema Registry not available
```bash
# Check if schema registry is running
docker logs schema-registry

# Restart services
docker-compose restart schema-registry
```

### Issue: Kafka connection failed
```bash
# Check Kafka broker status
docker logs kafka

# Verify Kafka is listening
netstat -an | findstr 9092
```

### Issue: UI not updating
- Refresh browser (F5)
- Check browser console for errors
- Verify Flask server is running
- Ensure system is started via "START SYSTEM" button

---

## ğŸ“ Project Structure

```
kafka_assignment/
â”œâ”€â”€ docker-compose.yml          # Kafka ecosystem configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ order.avsc             # Avro schema definition
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer.py            # Kafka producer implementation
â”‚   â”œâ”€â”€ consumer.py            # Kafka consumer with retry/DLQ
â”‚   â”œâ”€â”€ dashboard.py           # Terminal-based dashboard
â”‚   â”œâ”€â”€ app.py                 # Flask web application
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html         # Web dashboard UI
â””â”€â”€ screenshots/               # Dashboard screenshots
    â”œâ”€â”€ dashboard_running.png
    â””â”€â”€ order_processing.png
```

---

## ğŸ” Key Implementation Details

### Producer (`src/producer.py`)
- Generates random orders from product catalog
- Uses AvroSerializer for message serialization
- Implements delivery callbacks for confirmation
- Configures acknowledgment and retry settings

### Consumer (`src/consumer.py`)
- Subscribes to `orders` topic
- Deserializes Avro messages
- Implements retry logic with tracking
- Sends failed messages to DLQ
- Calculates running average in real-time
- Manual offset commit after successful processing

### Web Application (`src/app.py`)
- Flask server with SocketIO
- Background threads for producer/consumer
- RESTful API for metrics polling
- Real-time updates every 500ms
- Start/Stop system controls

---

## ğŸ“š Technologies Used

| Technology | Version | Purpose |
|------------|---------|---------|
| Apache Kafka | 7.5.0 | Message streaming platform |
| Confluent Schema Registry | 7.5.0 | Avro schema management |
| Python | 3.12 | Programming language |
| Flask | 3.0.0 | Web framework |
| Flask-SocketIO | 5.3.5 | Real-time communication |
| confluent-kafka | 2.3.0 | Kafka client library |
| Docker | Latest | Containerization |

---

## ğŸ“ Assignment Requirements Compliance

| Requirement | Implementation | Status |
|-------------|----------------|--------|
| Avro Serialization | Schema Registry + AvroSerializer/Deserializer | âœ… Complete |
| Real-time Aggregation | Running average of prices | âœ… Complete |
| Retry Logic | 3 retries with exponential backoff | âœ… Complete |
| Dead Letter Queue | orders-dlq topic for failed messages | âœ… Complete |
| Live Demonstration | Web-based dashboard with metrics | âœ… Complete |
| Git Repository | GitHub with full source code | âœ… Complete |

---

## ğŸ‘¤ Author

**Student ID:** EG/2020/3833  
**Repository:** https://github.com/Asam8385/Kafka_assignment_3833

---

## ğŸ“ License

This project is created for educational purposes as part of a university assignment.

---

## ğŸ™ Acknowledgments

- Apache Kafka documentation
- Confluent Platform guides
- Flask and SocketIO communities

---

## ğŸ“ Support

For questions or issues, please create an issue in the GitHub repository.

---

**Last Updated:** November 21, 2025